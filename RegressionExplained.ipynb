{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "082e9594-9b5c-4e74-b247-1b6cb5450384",
   "metadata": {},
   "source": [
    "# Introduction to Regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f7fe5-85a5-42b2-8c9a-d87017354c18",
   "metadata": {},
   "source": [
    "## How Regression analysis works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbd9f6b7-b12f-4a5b-bdf5-d547365d4c7f",
   "metadata": {},
   "source": [
    "- **Relationship Between Variables**: Regression analysis examines the relationship between a dependent variable (Y) and one or more explanatory variables (X).\n",
    "- **Graphical Representation**: Data can be visualized on a graph to show the relationship between Y and X. The slope of the line of best fit represents this relationship.<img src=\"imgs/reg1.png\" width=\"650\">\n",
    "- **Simple vs. Multiple Regression**: Simple regression involves one X variable, while multiple regression involves multiple X variables, allowing for more complex analysis.\n",
    "- **Lines and Planes of Best Fit**: Regression analysis fits lines (in simple regression) or planes (in multiple regression) to the data, summarizing the relationships between variables.<img src=\"imgs/reg2.png\" width=\"650\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d7752-43a2-4ee5-8248-924f67cb5437",
   "metadata": {},
   "source": [
    "## What regression analysis looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfbcc9-bbdf-46c8-906d-c03a0c44b168",
   "metadata": {},
   "source": [
    "- **Regression Output Sections**: Regression results are typically split into two sections: diagnostic information (e.g., sum of squares, R-squared, observation count) and the results (e.g., coefficients, standard errors).\n",
    "- **Key Statistics**: Important statistics include R-squared (indicates model fit), F statistic (predictive power), and root mean square error (size of residuals).\n",
    "- **Coefficients and Standard Errors**: The coefficient shows the relationship between each variable and the dependent variable (Y). The standard error indicates the accuracy of these coefficients.\n",
    "- **Statistical Significance**: Variables are statistically significant if t statistics are over 1.96, P values are below 0.05, or confidence intervals do not overlap with zero.\n",
    "- **Presentation Formats**: Regression results can be presented in various formats, such as tables in reports or outputs from statistical software like Stata.<img src=\"imgs/reg3.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb44fa-c949-4baa-84f5-bcefd81d4710",
   "metadata": {},
   "source": [
    "## Types of regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f19fc5-daad-48ef-8a7d-912f1eca53c9",
   "metadata": {},
   "source": [
    "- **Ordinary Least Squares (OLS)**: The most common regression method, used for continuous dependent variables and cross-sectional data.\n",
    "- **Non-Linear Methods**: Includes logit, probit, ordered logit, and multinomial logit models, used when the dependent variable is not continuous.\n",
    "- **Panel Regression Models**: Used for data collected repeatedly over time, revealing time dynamics.\n",
    "- **Count Data Models** Such as Poisson and negative binomial regression, used for non-negative integer data.\n",
    "- **Cox Proportional-Hazard Regression**: Used when the dependent variable is time, common in health sciences for survival analysis.\n",
    "  <img src=\"imgs/reg4.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad91f0d-4c70-463e-88ea-411cd7d5dbe2",
   "metadata": {},
   "source": [
    "## Correlation is not causation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da7caa-c012-444f-be64-70294630302a",
   "metadata": {},
   "source": [
    "- **Correlation vs. Causation**: Regression analysis shows correlation, not causation. It helps understand relationships between variables but doesn't prove one causes the other.\n",
    "- **Interpreting Causality**: Causality is often inferred through theoretical reasoning and common sense, not just statistics.\n",
    "- **Simultaneity**: Causality can flow in both directions, making it complex to determine which variable affects the other.\n",
    "- **Importance of Logic**: Logical reasoning, care, and sometimes even philosophy are essential to attribute causality in regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41d296-da38-4300-aaf1-bfc0d5fb46f5",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feaba5d-3719-4a9d-8916-9e51e106cd4f",
   "metadata": {},
   "source": [
    "## Fitting lines on a scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c25771-1f27-45c1-bda4-7855f2776102",
   "metadata": {},
   "source": [
    "- **Parametric vs. Non-Parametric Methods**: Parametric methods apply parameters to the data, making them suitable for multidimensional data and easy to communicate. Non-parametric methods allow the data to speak for itself, requiring fewer assumptions but are less effective in multidimensional environments.<br>\n",
    "**Advantages and Disadvantages**:\n",
    "    - **Parametric**: Works well with many variables and is easily transposable but requires strong assumptions about data shape.\n",
    "    - **Non-Parametric**: Requires fewer assumptions but is harder to communicate and less effective with many variables.\n",
    "- **Application in Regression**: Most regression methods use parametric fits to estimate parameters that indicate relationships between variables, making it easier to understand without visualizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015700e-e603-4407-a850-0be66986e7ce",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg5.png\" width=650>\n",
    "    <figcaption align=\"center\">Non-Parametric fit</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7a9d4-2a5f-4d82-a8bf-249b60d8f807",
   "metadata": {},
   "source": [
    "Non-parametric methods will use something called a *bandwidth* to compute a local average value in a small data space. This *bandwidth* is then traced across the data, and each average is stitched together.<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d259b0-d019-4c13-b827-3f9c671aaa38",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg6.png\" width=650>\n",
    "    <figcaption>Parametric fit</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e8110-9fa3-4796-9cd6-c41111e961ed",
   "metadata": {},
   "source": [
    "- Regression estimates **parameters** that **indicate the relationship between Y and X**.\n",
    "- The **slopes are often called coefficients**, which show the relationship between Y and X without having to look at the graph.\n",
    "\n",
    "This is the power of parametric fits. You don't need to visualize them. A parameter tells you what you need to know.<br>\n",
    "- Non-parametric methods should be used for graphical analysis of two variables.\n",
    "- Parametric methods should be used when you want to explore many variables at once in a regression framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9798a41-53a8-4ddd-bd24-07a64d61ceb7",
   "metadata": {},
   "source": [
    "## OLS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d559a-b6d9-4945-9ab1-b4b54f413ab0",
   "metadata": {},
   "source": [
    "- **OLS Regression**: It's a method to fit a line through data points by **minimizing the sum of squared residuals** (the differences between observed and predicted values).\n",
    "- **Residuals and Least Squares**: Residuals are the distances between the observed data points and the fitted line. Squaring these residuals removes negative values, and minimizing their sum helps find the best-fitting line.\n",
    "- **Parametric Method**: **OLS is a parametric method** that works with one or multiple variables, providing coefficients that describe the relationships between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c505e-47fe-4f32-8655-ac58edd44859",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg7.png\" width=650>\n",
    "    <figcaption>Residuals</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ccb024-8c81-47e2-9441-20b1b11ed5ce",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg8.png\" width=650>\n",
    "    <figcaption>Residual sum of squares</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105049a-d55a-4b20-9242-ef40047df4ec",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg9.png\" width=650>\n",
    "    <figcaption>Least squares</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94fbb8-97ae-40e7-9dc1-94b4028c4cc7",
   "metadata": {},
   "source": [
    "## BLUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef19428-46dd-4c0b-a617-7dac513fe15f",
   "metadata": {},
   "source": [
    "**BLUE Definition**: BLUE stands for **Best Linear Unbiased Estimator**.<br>\n",
    "It means that under certain conditions, the *ordinary least squares (OLS)* estimator is the best method for estimating the parameters of a regression model.<br>\n",
    "\n",
    "**Conditions for BLUE**: Four main conditions must be met for OLS to be BLUE:\n",
    "1. **Linearity**: The parameters must be linear. A dependent variable must be a continuously measured variable.\n",
    "    - **Dependent variable**: This is the outcome you're trying to predict or explain. In regression, it's often called the **target** or **label**.\n",
    "    - **Continuously measured variable**: This means the variable can take on any value within a range, including decimals. Examples include height, temperature, price, or time.<br>\n",
    "If the dependent variable is **categorical** (e.g., \"yes\"/\"no\", or \"low\"/\"medium\"/\"high\"), you'd need a different type of model—like **logistic regression** or **classification algorithms**.\n",
    "3. **Zero Conditional Mean (Exogeneity)**: There should be no correlation between explanatory variables and the error term.\n",
    "    - **Explanatory variables** (also called **independent variables** or **features**) are the inputs used to predict the outcome.\n",
    "    - The **error term** represents all the factors that **affect the dependent variable but are not included in the model**.\n",
    "    - **Endogeneity** means the variable is correlated with the error term, which may include unseen or omitted variables.\n",
    "5. **Homoscedasticity**: The variation of noise in the data must remain stable across explanatory variables.\n",
    "    - **Noise** = the error term (difference between actual and predicted values).\n",
    "    - **Stable variation** = the variance of the errors should not increase or decrease systematically with the explanatory variables.\n",
    "7. **No Collinearity**: Explanatory variables should not be highly correlated with each other.\n",
    "\n",
    "**Practical Application**: In practice, these conditions are rarely fully met, which means that OLS results often need moderation and holistic interpretation rather than being taken as absolute truth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8257b-2c06-4e78-be5c-6e7a62adf5d6",
   "metadata": {},
   "source": [
    "### Simulation example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90eca8-4f1d-4994-a16b-a4c389f40a23",
   "metadata": {},
   "source": [
    "1. Take a small sample from infinite data\n",
    "2. Estimate a particular relationship\n",
    "3. Use two hypothetical estimators\n",
    "4. The true parameter is one\n",
    "5. Plot the estimates on a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e119b-82ef-473a-87d6-537a9e6e9b32",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg10.png\" width=650 align=\"center\">\n",
    "    <figcaption>Efficiency graph</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842cbb46-d675-4aa4-834c-e0fadbb8b913",
   "metadata": {},
   "source": [
    "Both estimators, *on average*, estimate the correct value of one.<br>\n",
    "**However, the inefficient estimator is, *on average*, further away with its predictions than the efficient estimator**.<br>This is the concept of efficiency.<br>\n",
    "Normally we don't have an infinite amount of data, but in the real world, this concept is visible through higher or lower standard errors. Lower standard errors means more certainty around results.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548304dd-c1f3-49e4-8a71-89338d3b528a",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg11.png\" width=650>\n",
    "    <figcaption>Bias graph</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b093e-96af-4c06-b9d8-3ba388aff0a6",
   "metadata": {},
   "source": [
    "**The biased estimator, *on average*, does not estimate the true parameter in this data.**<br>\n",
    "*On average*, it's wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dcda6f-89e6-42b8-8eb0-16045f74c654",
   "metadata": {},
   "source": [
    "## Which conditions matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f263f4d-30ad-41e3-8977-c8b1c3792d44",
   "metadata": {},
   "source": [
    "**Gauss Markov Assumptions**: These are conditions that make OLS regression the best linear unbiased estimator (BLUE). **Not all assumptions are equally important in practice**.\n",
    "- **Homoscedasticity**: This assumption is less critical in real life. It assumes constant noise around the regression line. Modern statistical software can test and correct for violations of this assumption.\n",
    "- **No Collinearity**: This assumption is more significant. It requires that explanatory variables are not highly correlated. High collinearity can lead to noisier estimates and higher standard errors.\n",
    "    - It matters in small data sets (<100). Larger sets are unlikely to be affected. \n",
    "- **Linear in Parameters**: **This must be true for OLS to work**. It means that a one-unit change in an explanatory variable should consistently cause a change in the dependent variable - coefficients should have the same meaning across the regression space.\n",
    "- **Exogeneity**: **This is the most critical assumption**. It requires no correlation between explanatory variables and the error term. Violations can lead to biased estimates and significant issues in regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00513936-2e73-40a9-bade-bfae27ddff80",
   "metadata": {},
   "source": [
    "### Why exogeneity matters most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82f766-3de5-4b9a-8b8e-76a0c205b4bb",
   "metadata": {},
   "source": [
    "- **Exogeneity Assumption**: This is crucial for regression models. It requires that explanatory variables are not correlated with unseen variables outside the model.\n",
    "- **Endogeneity Consequences**: When the exogeneity assumption fails (endogeneity), it leads to biased estimates, meaning the coefficients do not have a causal interpretation, which can result in incorrect conclusions.\n",
    "- **Practical Implications**: Endogeneity is particularly problematic in applied work involving human behavior. Good regression models rely on theoretical frameworks, prior literature, and rational thought to address this issue.\n",
    "- **Exogeneity cannot be tested for**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c0098c-6921-4b82-9450-5bc3920fcd77",
   "metadata": {},
   "source": [
    "Suppose we're modeling student test scores based on hours studied:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ecee8-416b-4216-b351-f73470bbb2f7",
   "metadata": {},
   "source": [
    "$TestScore = β0 + β1 * HoursStudied + ε$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fd6ab-db13-4d91-86f2-904ab2800aa1",
   "metadata": {},
   "source": [
    "Here, $ε$ is the error term, which captures all other factors that influence $TestScore$ but are not included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d6b88-5330-4281-a285-d2373c56b694",
   "metadata": {},
   "source": [
    "$ε$ could be:\n",
    "- Student's prior knowledge or IQ\n",
    "- Quality of instruction or tutoring\n",
    "- Sleep quality before the test\n",
    "- Test anxiety\n",
    "- Nutrition or health on test day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa264ed2-1b49-49f3-a9c2-5a599fd85b53",
   "metadata": {},
   "source": [
    "If any of these omitted factors are correlated with $HoursStudied$ (e.g., smarter students tend to study more), then $HoursStudied$ becomes endogenous, and the OLS estimate of $β1$ will be biased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8156b-ca64-4910-909c-84cc5a17ff89",
   "metadata": {},
   "source": [
    "Variables that are likely to be endogenous are those that resemble choices made by firms, individuals, or nations. For example:\n",
    "\n",
    "- **Advertising Expenditure**: This can be influenced by various factors such as price changes and consumer preferences.\n",
    "- **Sales Performance**: This is driven by multiple factors, including advertising quality and external market conditions.\n",
    "\n",
    "These variables are often influenced by unseen factors, making them endogenous and potentially leading to biased estimates in regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e885976-9661-4d9d-b309-d13d9a031156",
   "metadata": {},
   "source": [
    "## Goodness-of-fit statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f8fbb-a420-41c0-b5af-6ac8c8ee0a96",
   "metadata": {},
   "source": [
    "- **R-squared Value**: This measures the goodness of fit in a regression model, ranging from 0 (poor fit) to 1 (perfect fit). It indicates **how much of the variation in the dependent variable is explained by the model**.\n",
    "- **Limitations of R-squared**: High R-squared values can be misleading if the model is overloaded with variables. Low R-squared values do not necessarily invalidate the model's coefficients.\n",
    "- **Contextual Use**: Use R-squared for contextual purposes, comparing it with typical values in your field, but focus more on the significance and magnitude of the coefficients.\n",
    "    - **Macro and Time Series Data Models**: These often have high R-squared values, typically around 0.8 or 0.9.\n",
    "    - **Micro and Cross-Sectional Data Models**: These usually have lower R-squared values, often around 0.2 or 0.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dbbd25-cf3a-4a79-af1b-ed124e62f3d6",
   "metadata": {},
   "source": [
    "When evaluating the coefficients in a regression model, consider asking the following questions:\n",
    "\n",
    "- **Do they make sense?**: Assess whether the coefficients align with your expectations and theoretical understanding.\n",
    "- **Are they significant?**: Check if the coefficients are statistically significant. If not, investigate further to understand why.\n",
    "- **Are they large?**: Evaluate the magnitude of the coefficients. Unexpectedly large coefficients might indicate a modeling error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec33650-53a5-4949-808c-cf58f19ffa96",
   "metadata": {},
   "source": [
    "## Using functional forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5cb19-b38c-4640-aeb5-2f6397ea84d1",
   "metadata": {},
   "source": [
    "- **Flexibility of Linear Regression**: Linear regression can fit many kinds of non-linear relationships, known as functional forms.\n",
    "- **Quadratic Relationships**: Introducing quadratic terms (e.g., mileage squared) can improve the model fit for non-linear data.\n",
    "- **Visual Representation**: It's important to display estimates visually to understand complex relationships better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d28a0-75fb-4479-89d8-856420c2a6cc",
   "metadata": {},
   "source": [
    "# OLS Tips and Tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89705ea-b6a3-41a7-afc2-0cd0ab968e9a",
   "metadata": {},
   "source": [
    "## Visualizing coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa41f44-1f4b-4679-bb19-79d3031b4705",
   "metadata": {},
   "source": [
    "### Simplify Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf08d550-8056-4522-8bc4-b5370d86af4a",
   "metadata": {},
   "source": [
    "Ensure regression tables are easy to read by clearly identifying dependent variables, presenting only important results, and using appropriate formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24be9e-e810-4d0d-bd7b-ad5271064eea",
   "metadata": {},
   "source": [
    " - **Clear Identification**: Clearly identify the dependent variable in the title of the table.\n",
    " - **Relevant Results**: Present only the important results that matter and that you want to discuss.\n",
    " - **Simplified Controls**: Use text to state that other controls are included, rather than listing them all.\n",
    " - **Decimal Places**: Present results to two or three decimal places only.\n",
    " - **Standard Errors**: Report standard errors only, not T statistics, confidence intervals, or P values. Use asterisks to indicate significance.\n",
    " - **Formatting**: Use appropriate borders: lines—heavy for top and bottom, thin to separate output from diagnostics.\n",
    " - **Naming Conventions**: Keep the naming conventions simple and relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c6f21-ff93-4b6e-965e-03d20a6dec8f",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg12.png\" width=650>\n",
    "    <figcaption>Correctly formated table</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e257f4e7-52f2-4028-ac13-34c68a6450c8",
   "metadata": {},
   "source": [
    " - **Use Visuals**: Besides tables, visualize regression results through plots to better understand relationships and coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1357c-cee5-4548-b30f-446d1f9ed442",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg13.png\" width=650>\n",
    "    <figcaption>Regression plot</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bae0f7-0e74-4aaf-a47f-73b8837a5cc8",
   "metadata": {},
   "source": [
    "## Rule of thumb significance check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71465a93-8673-4428-91e0-1afcd8b09f59",
   "metadata": {},
   "source": [
    "- **Statistical Testing**: It is crucial for determining if a variable is significantly different from zero or another variable.\n",
    "- **Quick Determination**: A shortcut for large samples (above 100) involves using a confidence interval to quickly assess statistical significance.\n",
    "- **Confidence Interval**: By doubling the standard error and adding/subtracting it from the coefficient, you can determine if a value is statistically different from zero or another value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f14130-22d5-42f6-82d6-02623f7d2cb2",
   "metadata": {},
   "source": [
    "To quickly determine if a coefficient is statistically significant, use the following method:\n",
    "\n",
    "1. **Estimate the Coefficient**: Identify the estimated coefficient and its standard error.\n",
    "2. **Calculate the Confidence Interval**: Multiply the standard error by 2 (approximately 1.96 for a 95% confidence interval) and add/subtract this value from the estimated coefficient.\n",
    "3. **Assess Significance**: If the confidence interval does not include zero, the coefficient is statistically significant.<br>\n",
    "**Practical Use**: This method is useful when scanning regression outputs without diving into exact p-values.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7f238-363b-4f2d-9221-fcb81d0e235b",
   "metadata": {},
   "source": [
    "**Key Points**:\n",
    "\n",
    "**Overlapping Confidence Intervals ≠ No Difference**<br>\n",
    "Overlap between confidence intervals does not necessarily mean the coefficients are statistically indistinguishable. It just means that each coefficient, individually, might not be significantly different from some values—including possibly each other.\n",
    "\n",
    "**Comparing Coefficients Requires a Different Test**<br>\n",
    "If you want to test whether two coefficients are significantly different from each other, you need to perform a *contrast test* or a *hypothesis test* on the difference between them. This is more precise than just eyeballing overlapping intervals.<br>\n",
    "In Python, using `statsmodels`, you can do this with a *Wald test* or by manually computing the standard error of the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2528561e-07ab-41df-9439-d2b373f5d22d",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg14.png\" width=650>\n",
    "    <figcaption>Statistical significance assumption</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c1d1d-efe1-4565-b35b-7b0ba13a9ac9",
   "metadata": {},
   "source": [
    "## Reading indicator variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e88ec-c0ae-4fe9-af6c-3a83f43caa7b",
   "metadata": {},
   "source": [
    "- **Indicator Variables**: Also known as dummy variables, these take values of 0 or 1 and are used to analyze non-continuous data.\n",
    " - **Interpretation**: The coefficient of an indicator variable shows the effect relative to a reference category, shifting the regression line up or down.\n",
    " - **Multiple Categories**: When dealing with variables with multiple categories (e.g., regions), they need to be recoded into separate dummy variables, with one excluded as the reference category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a20550-49ee-43d4-b2a4-e8835fa04888",
   "metadata": {},
   "source": [
    "## Make use of time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6c09e-0855-43b6-a793-bd179864a6ba",
   "metadata": {},
   "source": [
    " - **Cross-Sectional Data**: Data collected at a single point in time across multiple subjects (e.g., people, companies, regions).\n",
    "    - **Example**: Income levels of 100 households in 2025.\n",
    " - **Time Series Data**: Unlike cross-sectional data, time series data involves repeated measurements over time, allowing for the investigation of time dynamics.\n",
    "     - **Example**: Daily temperature in Tomaszkowo for the year 2025.\n",
    " - **Lagged Variables**: These are past values of variables used to understand how past events affect current outcomes. For example, living in an urban area last year might impact wages today.\n",
    " - **Time Dynamics**: Introducing time into regression models helps analyze cause and effect more accurately, showing that some effects, like wage increases from moving to an urban area, take time to materialize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a52c4-9d48-4d0c-a15a-c603e9f5c749",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d87cfc-4d6c-4570-93eb-7a36063262c0",
   "metadata": {},
   "source": [
    "In this regression, we control for various demographic factors and different regions. There are also two variables for living in an urban area:\n",
    " - A **contemporaneous variable** called *urban time zero*\n",
    " - A **lagged variable** called *urban time minus one*.<br>\n",
    "Here, time is measured in years, so *T minus one* refers to last year.<br>\n",
    "What these results say is once demographic and regional factors are controlled for, living in an urban area today has no impact on current hourly wages, but living in an urban area last year increases today's wages by around 5.5%<br>\n",
    "This is evidence that the effect of moving from a rural area to an urban area takes one year to materialize. It's not instantaneous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69897372-d1c8-44f3-bde3-76087cd69c5a",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg15.png\" width=650>\n",
    "    <figcaption>Lagged time regression</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef90819-3779-47fe-bc46-dc7e7f57e05e",
   "metadata": {},
   "source": [
    "## Interpreting elasticities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0992fa-198a-40d6-80c0-9329f8920337",
   "metadata": {},
   "source": [
    " - **Elasticity Concept**: Elasticity measures the proportional change of one variable in response to a change in another variable. It's commonly used in economic and business modeling.\n",
    " - **Log Transformations**: Log transformations in regression analysis allow results to be interpreted in terms of elasticities. There are four types of models:\n",
    "     - **Linear Model**: No transformation; coefficients relate to unit changes.\n",
    "     - **Log-Linear Model**: Regresses log Y against X; coefficients indicate percentage change in Y for a unit change in X.\n",
    "     - **Linear-Log Model**: Regresses Y against log X; coefficients indicate unit change in Y for a percentage change in X.\n",
    "     - **Log-Log Model**: Regresses log Y against log X; coefficients indicate percentage change in Y for a percentage change in X.\n",
    "\n",
    "**Practical Application**: Understanding these models helps in interpreting how changes in one variable affect another, which is crucial for business and economic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc15f8d-8901-4c6d-bbec-3de6d9705a35",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/reg16.png\" width=650>\n",
    "    <figcaption>Common regression transformations</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b3887-cff9-4b20-abe8-7a72ac57fa83",
   "metadata": {},
   "source": [
    "# Applied Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6e5da-4fe7-49c3-b88a-e6b242b276ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
