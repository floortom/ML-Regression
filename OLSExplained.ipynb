{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165ee6ed-d407-4477-bedf-f3c441d1cf94",
   "metadata": {},
   "source": [
    "# Understanding Components of OLS Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a420b-42fc-4c79-898c-ed674b952a8e",
   "metadata": {},
   "source": [
    "**The OLS summary report is a detailed output that provides various metrics and statistics to help evaluate the model's performance and interpret its results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35e7c5-99de-47c8-8e34-a75eae5e7709",
   "metadata": {},
   "source": [
    "```\n",
    "OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                      y   R-squared:                       0.669\n",
    "Model:                            OLS   Adj. R-squared:                  0.667\n",
    "Method:                 Least Squares   F-statistic:                     299.2\n",
    "Date:                Mon, 01 Mar 2021   Prob (F-statistic):           2.33e-37\n",
    "Time:                        16:19:34   Log-Likelihood:                -88.686\n",
    "No. Observations:                 150   AIC:                             181.4\n",
    "Df Residuals:                     148   BIC:                             187.4\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         -3.2002      0.257    -12.458      0.000      -3.708      -2.693\n",
    "x1             0.7529      0.044     17.296      0.000       0.667       0.839\n",
    "==============================================================================\n",
    "Omnibus:                        3.538   Durbin-Watson:                   1.279\n",
    "Prob(Omnibus):                  0.171   Jarque-Bera (JB):                3.589\n",
    "Skew:                           0.357   Prob(JB):                        0.166\n",
    "Kurtosis:                       2.744   Cond. No.                         43.4\n",
    "==============================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a09b28-4385-4081-94c5-5d82ef8d6a6a",
   "metadata": {},
   "source": [
    "## The Header Section: Dependent Variable and Model Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605dcab4-a1c9-4fb9-b820-e1cfe9bb8ac7",
   "metadata": {},
   "source": [
    "- **Dependent Variable and Model:** The dependent variable (also known as the explained variable) is the variable that we aim to predict or explain using the independent variables. The model section indicates that the method used is *Ordinary Least Squares (OLS)*, which minimizes the sum of the squared errors between the observed and predicted values.\n",
    "- **Number of observations:** The number of observation is the size of our sample, i.e. N = 150.\n",
    "- **Degrees of freedom(df):** Degree of freedom is the number of independent observations on the basis of which the sum of squares is calculated.<br>\n",
    "\n",
    "Degrees of freedom: \n",
    "$$\n",
    "Df = N − K Df =N−K\n",
    "$$\n",
    "*Where **N** = sample size(no. of observations) and  **K** = number of variables + 1 (including the intercept).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee41fa-15e1-4f88-9ed4-e70ecb3d0fdc",
   "metadata": {},
   "source": [
    "## Coefficient Interpretation: Standard Error, T-Statistics, and P-Value Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b4c1c-6f36-4427-867a-e5add7a7ef36",
   "metadata": {},
   "source": [
    "```\n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         -3.2002      0.257    -12.458      0.000      -3.708      -2.693\n",
    "x1             0.7529      0.044     17.296      0.000       0.667       0.839\n",
    "==============================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8010a3d-50f9-42a2-9fed-2f899fec8cce",
   "metadata": {},
   "source": [
    "- **Constant term:** The constant terms is the intercept of the regression line. In regression we omits some independent variables that do not have much impact on the dependent variable, the intercept tells the average value of these omitted variables and noise present in model. For example, in the regression equation $$Y = 5.0 + 0.75X$$ , the constant term (intercept) of 5.0 indicates that when X=0, the predicted value of Y is 5.0, representing the baseline level influenced by omitted factors.\n",
    "- **Coefficient term:** The coefficient term tells the change in Y for a unit change in X. For Example, if X rises by 1 unit then Y rises by 0.7529.\n",
    "- **Standard Error of Parameters:** Standard error is also called the standard deviation. It is a measure of how much the coefficient estimates would vary if the same model were estimated with different samples from the same population. Larger standard errors indicate less precise estimates. Standard error is calculated by as:\n",
    "$$\n",
    "Standard Error = \\sqrt{\\frac{N-K}{Residual Sum of Squares}} \\cdot \\sqrt{\\frac{1}{\\displaystyle\\sum(X_1-\\overline{X})^2}}\n",
    "$$\n",
    "*where:*\n",
    "- ***Residual Sum of Squares** is the sum of the squared differences between the observed values and the predicted values.*\n",
    "- ***N** is the number of observations.*\n",
    "- ***K** is the number of independent variables in the model, including the intercept.*\n",
    "- ***$X_i$** represents each independent variable value, and **$\\overline{X}$** is the mean of those values.*\n",
    "- **T-Statistics and P-Values:**\n",
    "    - The t-statistics are calculated by dividing the coefficient by its standard error. These values are used to test the null hypothesis that the coefficient is zero (i.e., the independent variable has no effect on the dependent variable).\n",
    "    - The p-values associated with these t-statistics indicate the probability of observing the estimated coefficient (or a more extreme value) if the null hypothesis were true. A p-value below a certain significance level (usually 0.05) suggests that the coefficient is statistically significant, meaning the independent variable has a significant effect on the dependent variable.\n",
    "- **Confidence Intervals:** The confidence intervals give a range within which the true coefficient likely falls, with a certain level of confidence (usually 95%).\n",
    "    - If a confidence interval includes zero, it means there’s a chance the variable might not actually impact the outcome.\n",
    "    - If zero isn’t in the interval, it’s more likely that the variable genuinely affects the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef8a8b-2212-431c-8626-5f135d0874e3",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance: Goodness of Fit Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f54b6-cb9a-4839-b81d-c0be8b4ca340",
   "metadata": {},
   "source": [
    "```\n",
    "==============================================================================\n",
    "Dep. Variable:                      y   R-squared:                       0.669\n",
    "Model:                            OLS   Adj. R-squared:                  0.667\n",
    "Method:                 Least Squares   F-statistic:                     299.2\n",
    "Date:                Mon, 01 Mar 2021   Prob (F-statistic):           2.33e-37\n",
    "Time:                        16:19:34   Log-Likelihood:                -88.686\n",
    "No. Observations:                 150   AIC:                             181.4\n",
    "Df Residuals:                     148   BIC:                             187.4\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e248b89-c22e-4567-95f6-159e1be941be",
   "metadata": {},
   "source": [
    "- **R-Squared (R²):** R-squared measures the proportion of the variance in the dependent variable that is explained by the independent variables. It ranges from 0 to 1, where 1 indicates that the model explains all the variance.\n",
    "- **Adjusted R-Squared:** Adjusted R-squared is a modified version of R-squared that adjusts for the number of independent variables in the model, providing a more accurate measure of the model's explanatory power when comparing models with different numbers of variables.\n",
    "    - For example, an R-squared value of 0.669 means that about 66.9% of the variance in the dependent variable is explained by the model.\n",
    "    - If the adjusted R-squared decreases when adding more variables, it suggests that the additional variables do not contribute significantly to the model and may be omitted.\n",
    "- **F-Statistic and Prob(F-Statistic):** The F-statistic is used to test the overall significance of the model. The null hypothesis is that all coefficients (except the intercept) are zero, meaning the model does not explain any variance in the dependent variable. The p-value associated with the F-statistic indicates the probability of observing the F-statistic (or a more extreme value) if the null hypothesis were true. A small p-value (typically less than 0.05) indicates that the model is statistically significant, meaning at least one of the independent variables has a significant effect on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1005761-bb2d-4d56-b0fb-2210750cfa74",
   "metadata": {},
   "source": [
    "## Testing Model Assumptions with Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0399116-9869-489d-a60a-cecb1bcfe784",
   "metadata": {},
   "source": [
    "```\n",
    "==============================================================================\n",
    "Omnibus:                        3.538   Durbin-Watson:                   1.279\n",
    "Prob(Omnibus):                  0.171   Jarque-Bera (JB):                3.589\n",
    "Skew:                           0.357   Prob(JB):                        0.166\n",
    "Kurtosis:                       2.744   Cond. No.                         43.4\n",
    "==============================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28548aaf-d9d0-4401-9670-acaf5c5ba82a",
   "metadata": {},
   "source": [
    "The remaining terms are not often used. Ordinary Least Squares (OLS) summary provides several diagnostic checks to help assessspecific assumptions about the data. Terms like Skewness and Kurtosis tells about the distribution of data. Below are key diagnostics included in the OLS summary:\n",
    "- **Omnibus:** The Omnibus test evaluates the joint normality of the residuals. A higher value suggests a deviation from normality.\n",
    "- **Prob(Omnibus):** This p-value indicates the probability of observing the test statistic under the null hypothesis of normality. A value above 0.05 suggests that we do not reject the null hypothesis, implying that the residuals may be normally distributed.\n",
    "- **Jarque-Bera (JB):** The Jarque-Bera test is another test for normality that assesses whether the sample skewness and kurtosis match those of a normal distribution.\n",
    "- Prob(JB): Similar to the Prob(Omnibus), this p-value assesses the null hypothesis of normality. A value greater than 0.05 indicates that we do not reject the null hypothesis.\n",
    "- **Skew:** Skewness measures the asymmetry of the distribution of residuals. A skewness value close to zero indicates a symmetrical distribution, while positive or negative values indicate right or left skewness, respectively.\n",
    "- **Kurtosis:** Kurtosis measures the \"tailedness\" of the distribution. A kurtosis value of 3 indicates a normal distribution, while values above or below suggest heavier or lighter tails, respectively.\n",
    "- **Durbin-Watson**: This statistic tests for autocorrelation in the residuals from a regression analysis. Values close to 2 suggest no autocorrelation, while values less than 1 or greater than 3 indicate positive or negative autocorrelation, respectively.\n",
    "- **Cond. No.:** The condition number assesses multicollinearity, where values above 30 suggest potential multicollinearity issues among the independent variables.<br>\n",
    "***Skewness and kurtosis for the normal distribution are 0 and 3 respectively.***<br> These diagnostic tests are essential for validating the reliability of a linear regression model, helping ensure that the model's assumptions are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4038a2d-fc2b-4a64-816e-af67c4d6f177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
